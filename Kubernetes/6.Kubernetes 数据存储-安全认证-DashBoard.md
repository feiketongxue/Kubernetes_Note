# 1. 数据存储

容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes 引入了 Volume 的概念。

Volume 是 Pod 中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes 通过 Volume 实现同一个 Pod 中不同容器之间的数据共享以及数据的持久化存储。Volume 的生命容器不与 Pod 中单个容器的生命周期相关，当容器终止或者重启时，Volume 中的数据也不会丢失。

kubernetes 的 Volume 支持多种类型，比较常见的有下面几个：

- 简单存储：EmptyDir、HostPath、NFS
- 高级存储：PV、PVC
- 配置存储：ConfigMap、Secret

## 1.1 基本存储

### 1.1.1 EmptyDir

EmptyDir 是最基础的 Volume 类型，一个 EmptyDir 就是 Host 上的一个空目录。

EmptyDir 是在Pod被分配到 Node 时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为 kubernetes 会自动分配一个目录，当 Pod 销毁时， EmptyDir 中的数据也会被永久删除。 EmptyDir 用途如下：

- 临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留
- 一个容器需要从另一个容器中获取数据的目录（多容器共享目录）
接下来，通过一个容器之间文件共享的案例来使用一下 EmptyDir。

在一个Pod中准备两个容器 nginx 和 busybox ，然后声明一个 Volume 分别挂在到两个容器的目录中，然后nginx 容器负责向 Volume 中写日志，busybox 中通过命令将日志内容读到控制台。

![1715244234733](../Images/image-20200413174713773.png)

```sh
# 创建 volume-emptydir.yaml 文件

apiVersion: v1
kind: Pod
metadata:
  name: volume-emptydir
  namespace: dev
spec:
  containers:
  - name: nginx
    image: nginx:1.17.1
    ports:
    - containerPort: 80
    volumeMounts:  # 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx
    - name: logs-volume
      mountPath: /var/log/nginx
  - name: busybox
    image: busybox:1.30
    command: ["/bin/sh","-c","tail -f /logs/access.log"] # 初始命令，动态读取指定文件中内容
    volumeMounts:  # 将logs-volume 挂在到busybox容器中，对应的目录为 /logs
    - name: logs-volume
      mountPath: /logs
  volumes: # 声明volume， name为logs-volume，类型为emptyDir
  - name: logs-volume
    emptyDir: {}

```

```sh



```
### 1.1.2 HostPath

EmptyDir 中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。

HostPath 就是将 Node 主机中一个实际目录挂在到 Pod 中，以供容器使用，这样的设计就可以保证 Pod 销毁了，但是数据依据可以存在于 Node 主机上。


![1715244234733](../Images/image-20200413214031331.png)

```sh
# 创建 volume-hostpath.yaml 文件
apiVersion: v1
kind: Pod
metadata:
  name: volume-hostpath
  namespace: dev
spec:
  containers:
  - name: nginx
    image: nginx:1.17.1
    ports:
    - containerPort: 80
    volumeMounts:
    - name: logs-volume
      mountPath: /var/log/nginx
  - name: busybox
    image: busybox:1.30
    command: ["/bin/sh","-c","tail -f /logs/access.log"]
    volumeMounts:
    - name: logs-volume
      mountPath: /logs
  volumes:
  - name: logs-volume
    hostPath: 
      path: /root/logs
      type: DirectoryOrCreate  # 目录存在就使用，不存在就先创建后使用
```

关于type的值的一点说明：

 - DirectoryOrCreate 目录存在就使用，不存在就先创建后使用
 - Directory   目录必须存在
 - FileOrCreate  文件存在就使用，不存在就先创建后使用
 - File 文件必须存在 
 - Socket  unix套接字必须存在
 - CharDevice  字符设备必须存在
 - BlockDevice 块设备必须存在

```sh
```
### 1.1.3 NFS

HostPath 可以解决数据持久化的问题，但是一旦 Node 节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用 NFS、CIFS。

NFS 是一个网络文件存储系统，可以搭建一台 NFS 服务器，然后将 Pod 中的存储直接连接到NFS系统上，这样的话，无论 Pod 在节点上怎么转移，只要 Node 跟 NFS 的对接没问题，数据就可以成功访问。

![20200413215133559](../Images/image-20200413215133559.png)

1. 
```sh
```
2. 
```sh
```
3. 
```sh
```
4. 
```sh
```

## 1.2 高级存储

前面已经学习了使用NFS提供存储，此时就要求用户会搭建NFS系统，并且会在yaml配置nfs。由于kubernetes支持的存储系统有很多，要求客户全都掌握，显然不现实。为了能够屏蔽底层存储实现的细节，方便用户使用， kubernetes引入PV和PVC两种资源对象。

- PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。

- PVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。

![20200514194111567](../Images/image-20200514194111567.png)

使用了PV和PVC之后，工作可以得到进一步的细分：

- 存储：存储工程师维护
- PV： kubernetes 管理员维护
- PVC：kubernetes 用户维护

### 1.2.1 PV

```sh
# PV是存储资源的抽象，资源清单文件:
apiVersion: v1  
kind: PersistentVolume
metadata:
  name: pv2
spec:
  nfs: # 存储类型，与底层真正存储对应
  capacity:  # 存储能力，目前只支持存储空间的设置
    storage: 2Gi
  accessModes:  # 访问模式
  storageClassName: # 存储类别
  persistentVolumeReclaimPolicy: # 回收策略
```

PV 的关键配置参数说明：

- 存储类型

    底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异

- 存储能力（capacity）

    目前只支持存储空间的设置( storage=1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置

- 访问模式（accessModes）

    用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：

    1. ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载
    2. ReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载
    3. ReadWriteMany（RWX）：读写权限，可以被多个节点挂载

需要注意的是，底层不同的存储类型可能支持的访问模式不同

- 回收策略（persistentVolumeReclaimPolicy）

    当PV不再被使用了之后，对其的处理方式。目前支持三种策略：

    1. Retain （保留） 保留数据，需要管理员手工清理数据
    2. Recycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/*
    3. Delete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务

需要注意的是，底层不同的存储类型可能支持的回收策略不同

- 存储类别

    PV 可以通过 storageClassName 参数指定一个存储类别

    1. 具有特定类别的PV只能与请求了该类别的PVC进行绑定
    2. 未设定类别的PV则只能与不请求任何类别的PVC进行绑定
- 状态（status）

    一个 PV 的生命周期中，可能会处于4中不同的阶段：

    1. Available（可用）： 表示可用状态，还未被任何 PVC 绑定
    2. Bound（已绑定）： 表示 PV 已经被 PVC 绑定
    3. Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明
    4. Failed（失败）： 表示该 PV 的自动回收失败


> **实验**
> 使用 NFS 作为存储，来演示 PV 的使用，创建 3个 PV ，对应 NFS 中的3个暴露的路径。
1. 准备 NFS 环境
```sh
```
2. 创建 pv.yaml 文件

```sh
```

```sh
```


### 1.2.2 PVC

PVC 是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:

```sh
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc
  namespace: dev
spec:
  accessModes:      # 访问模式
  selector:         # 采用标签对PV选择
  storageClassName: # 存储类别
  resources:        # 请求空间
    requests:
      storage: 5Gi
```

PVC 的关键配置参数说明：

- 访问模式（accessModes）
    用于描述用户应用对存储资源的访问权限

- 选择条件（selector）

    通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选

- 存储类别（storageClassName）

    PVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出

- 资源请求（Resources ）

    描述对存储资源的请求

> 实验

1. 创建 pvc.yaml 文件，申请 pv
```sh
```
2. 创建 pods.yaml 文件 , 使用 pv

```sh
```

### 1.2.3 生命周期

> PVC 和 PV 是一一对应的，PV 和 PVC 之间的相互作用遵循以下生命周期：

- 资源供应：管理员手动创建底层存储和PV

- 资源绑定：用户创建 PVC ，kubernetes 负责根据 PVC 的声明去寻找 PV，并绑定

    在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的

- 一旦找到，就将该 PV 与用户定义的 PVC 进行绑定，用户的应用就可以使用这个 PVC 了
- 如果找不到，PVC 则会无限期处于 Pending 状态，直到等到系统管理员创建了一个符合其要求的 PV

    PV一旦绑定到某个PVC上，就会被这个 PVC 独占，不能再与其他PVC进行绑定了

- 资源使用：用户可在 pod 中像 volume 一样使用 pvc

    Pod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。

- 资源释放：用户删除 pvc 来释放 pv

    当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。

- 资源回收：kubernetes 根据 pv 设置的回收策略进行资源的回收

    对于 PV，管理员可以设定回收策略，用于设置与之绑定的 PVC 释放资源之后如何处理遗留数据的问题。只有 PV 的存储空间完成回收，才能供新的 PVC 绑定和使用


![20200515002806726](../Images/image-20200515002806726.png)
## 1.3 配置存储

### 1.3.1 ConfigMap

> ConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。

```sh
# 创建 configmap.yaml 文件
apiVersion: v1
kind: ConfigMap
metadata:
  name: configmap
  namespace: dev
data:
  info: |
    username:admin
    password:123456
```

```sh




```
### 1.3.2 Secret

> 在 kubernetes 中，还存在一种和 ConfigMap 非常类似的对象，称为 Secret 对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。

```sh
# 使用base64对数据进行编码


```
```sh

# 创建 secret.yaml 文件
```

```sh


```

# 2. 安全认证

## 2.1 访问控制概述

Kubernetes 作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对 Kubernetes 的各种客户端进行认证和鉴权操作。

### 客户端

在Kubernetes集群中，客户端通常有两类：

User Account：一般是独立于 kubernetes 之外的其他服务管理的用户账号。
Service Account：kubernetes 管理的账号，用于为 Pod 中的服务进程在访问 Kubernetes 时提供身份标识。

![20200520102949189](../Images/image-20200520102949189.png)

### 认证、授权与准入控制

ApiServer是访问及管理资源对象的唯一入口。任何一个请求访问ApiServer，都要经过下面三个流程：

- Authentication（认证）：身份鉴别，只有正确的账号才能够通过认证
- Authorization（授权）： 判断用户是否有权限对访问的资源执行特定的动作
- Admission Control（准入控制）：用于补充授权机制以实现更加精细的访问控制功能。

![20200520103942580](../Images/image-20200520103942580.png)
## 2.2 认证管理

Kubernetes 集群安全的最关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式：
1. HTTP Base认证：通过用户名+密码的方式认证

    这种认证方式是把“用户名:密码”用BASE64算法进行编码后的字符串放在HTTP请求中的Header Authorization域里发送给服务端。服务端收到后进行解码，获取用户名及密码，然后进行用户身份认证的过程。

2. HTTP Token认证：通过一个Token来识别合法用户

    这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求时，需要在HTTP Header里放入Token，API Server接到Token后会跟服务器中保存的token进行比对，然后进行用户身份认证的过程。

3. HTTPS证书认证：基于CA根证书签名的双向数字证书认证方式

    这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式。

    ![20200518211037434](../Images/image-20200518211037434.png)


HTTPS认证大体分为3个过程：

1. 证书申请和下发
    
    HTTPS通信双方的服务器向CA机构申请证书，CA机构下发根证书、服务端证书及私钥给申请者

2. 客户端和服务端的双向认证

    1. 客户端向服务器端发起请求，服务端下发自己的证书给客户端，
     客户端接收到证书后，通过私钥解密证书，在证书中获得服务端的公钥，
     客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器
    2. 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书，
     在证书中获得客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法
3. 服务器端和客户端进行通信

    服务器端和客户端协商好加密方案后，客户端会产生一个随机的秘钥并加密，然后发送到服务器端。
    服务器端接收这个秘钥后，双方接下来通信的所有内容都通过该随机秘钥加密

> 注意: Kubernetes允许同时配置多种认证方式，只要其中任意一个方式认证通过即可
## 2.3 授权管理

授权发生在认证成功之后，通过认证就可以知道请求用户是谁， 然后Kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权。

每个发送到ApiServer的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。

API Server目前支持以下几种授权策略：

- AlwaysDeny：表示拒绝所有请求，一般用于测试
- AlwaysAllow：允许接收所有请求，相当于集群不需要授权流程（Kubernetes默认的策略）
- ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制
- Webhook：通过调用外部REST服务对用户进行授权
- Node：是一种专用模式，用于对kubelet发出的请求进行访问控制
- RBAC：基于角色的访问控制（kubeadm安装方式下的默认选项）

RBAC(Role-Based Access Control) 基于角色的访问控制，主要是在描述一件事情：给哪些对象授予了哪些权限,其中涉及到了下面几个概念：

- 对象：User、Groups、ServiceAccount
- 角色：代表着一组定义在资源上的可操作动作(权限)的集合
- 绑定：将定义好的角色跟用户绑定在一起

    ![20200519181209566](../Images/image-20200519181209566.png)

RBAC引入了4个顶级资源对象：

- Role、ClusterRole：角色，用于指定一组权限
- RoleBinding、ClusterRoleBinding：角色绑定，用于将角色（权限）赋予给对象
### Role、ClusterRole

一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单）。
```sh
# Role只能对命名空间内的资源进行授权，需要指定nameapce
kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  namespace: dev
  name: authorization-role
rules:
- apiGroups: [""]  # 支持的API组列表,"" 空字符串，表示核心API群
  resources: ["pods"] # 支持的资源对象列表
  verbs: ["get", "watch", "list"] # 允许的对资源对象的操作方法列表
```
```sh
# ClusterRole可以对集群范围内资源、跨namespaces的范围资源、非资源类型进行授权
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
 name: authorization-clusterrole
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
```

需要详细说明的是，rules中的参数：

- apiGroups: 支持的API组列表

```sh
"","apps", "autoscaling", "batch"
```
- resources：支持的资源对象列表

```sh
"services", "endpoints", "pods","secrets","configmaps","crontabs","deployments","jobs",
"nodes","rolebindings","clusterroles","daemonsets","replicasets","statefulsets",
"horizontalpodautoscalers","replicationcontrollers","cronjobs"
```

- verbs：对资源对象的操作方法列表

```sh
"get", "list", "watch", "create", "update", "patch", "delete", "exec"
```
### RoleBinding、ClusterRoleBinding

角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount。

```sh
# RoleBinding可以将同一namespace中的subject绑定到某个Role下，则此subject即具有该Role定义的权限
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: authorization-role-binding
  namespace: dev
subjects:
- kind: User
  name: heima
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: authorization-role
  apiGroup: rbac.authorization.k8s.io
```

```sh
# ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
 name: authorization-clusterrole-binding
subjects:
- kind: User
  name: heima
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: authorization-clusterrole
  apiGroup: rbac.authorization.k8s.io
```

#### RoleBinding引用 ClusterRole 进行授权
RoleBinding 可以引用 ClusterRole，对属于同一命名空间内 ClusterRole 定义的资源主体进行授权。

    一种很常用的做法就是，集群管理员为集群范围预定义好一组角色（ClusterRole），然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅提高授权管理工作效率，也使得各个命名空间下的基础性授权规则与使用体验保持一致。

```sh
# 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding
# 所以heima只能读取dev命名空间中的资源
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: authorization-role-binding-ns
  namespace: dev
subjects:
- kind: User
  name: heima
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: authorization-clusterrole
  apiGroup: rbac.authorization.k8s.io
```

> 实战：创建一个只能管理dev空间下Pods资源的账号

1. 创建账号
```sh

```
2. 创建 Role 和 RoleBinding，为 devman 用户授权
```sh

```
3. 切换账户，再次验证
```sh

```

## 2.4 准入控制

通过了前面的认证和授权之后，还需要经过准入控制处理通过之后，apiserver才会处理这个请求。

准入控制是一个可配置的控制器列表，可以通过在Api-Server上通过命令行设置选择执行哪些准入控制器：

```sh
--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,
                      DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds
```


只有当所有的准入控制器都检查通过之后，apiserver才执行该请求，否则返回拒绝。

当前可配置的Admission Control准入控制如下：

- AlwaysAdmit：允许所有请求
- AlwaysDeny：禁止所有请求，一般用于测试
- AlwaysPullImages：在启动容器之前总去下载镜像
- DenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求
- ImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能。
- Service Account：实现ServiceAccount实现了自动化
- SecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效
- ResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标
- LimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制
- InitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置
- NamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒绝。当删除一个namespace时，系统将会删除该namespace中所有对象。
- DefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认的 StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节
- DefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min
- PodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制

# 3. DashBoard

在 kubernetes 中完成的所有操作都是通过命令行工具 kubectl 完成的。其实，为了提供更丰富的用户体验，kubernetes 还开发了一个基于 web 的用户界面（Dashboard）。用户可以使用 Dashboard 部署容器化的应用，还可以监控应用的状态，执行故障排查以及管理 kubernetes 中各种资源。

## 3.1  部署 Dashboard

## 3.2  使用 DashBoard
